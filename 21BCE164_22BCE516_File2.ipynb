{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":793589,"sourceType":"datasetVersion","datasetId":57}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install hmmlearn","metadata":{},"execution_count":33,"outputs":[{"name":"stdout","output_type":"stream","text":"Collecting hmmlearn\n\n  Downloading hmmlearn-0.3.2-cp310-cp310-win_amd64.whl (124 kB)\n\n     ---------------------------------------- 0.0/124.5 kB ? eta -:--:--\n\n     ------------ ------------------------ 41.0/124.5 kB 653.6 kB/s eta 0:00:01\n\n     ----------------------------- ------ 102.4/124.5 kB 980.4 kB/s eta 0:00:01\n\n     -------------------------------------- 124.5/124.5 kB 1.0 MB/s eta 0:00:00\n\nRequirement already satisfied: scikit-learn!=0.22.0,>=0.16 in c:\\users\\rimple\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from hmmlearn) (1.2.2)\n\nRequirement already satisfied: numpy>=1.10 in c:\\users\\rimple\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from hmmlearn) (1.23.5)\n\nRequirement already satisfied: scipy>=0.19 in c:\\users\\rimple\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from hmmlearn) (1.10.1)\n\nRequirement already satisfied: joblib>=1.1.1 in c:\\users\\rimple\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (1.1.1)\n\nRequirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\rimple\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (2.2.0)\n\nInstalling collected packages: hmmlearn\n\nSuccessfully installed hmmlearn-0.3.2\n\nNote: you may need to restart the kernel to use updated packages.\n"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nfrom hmmlearn import hmm\n\n# Step 1: Data Preprocessing\n# Load dataset\ndata = pd.read_csv(\"Travel details dataset.csv\")\n\n# Clean dataset (remove missing values, outliers, etc.)\ndata.dropna(inplace=True)\n\n# Encode categorical variables\ndata = pd.get_dummies(data, columns=[\"Accommodation\", \"Gender\"])\n\n# Step 2: Feature Engineering\n# Select relevant features\nselected_features = [\"Duration\",\"Age\"] \n# selected_features = [\"Location\",\"Departure Time\", \"Travel Duration (hours)\",\"Arrival Time\",\"Purpose\",\"Mean of Trip\", \"Age\",\"Gender\",\"Occupation\",\"Car Ownership\"] # Add more features as needed\nX = data[selected_features].values\n\n# Normalize numerical features\n# You can use Min-Max scaling, Z-score normalization, or other techniques\n# Example of Min-Max scaling\nX = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n\n# Step 3: Training the HMM\n# Choose the number of hidden states\nn_states = 5\n\n# Initialize and train the HMM\nmodel = hmm.GaussianHMM(n_components=n_states, covariance_type=\"full\", n_iter=100)\nmodel.fit(X)\n\n# Step 4: Generating Sequences\n# Generate sequences of human activities\n# You can specify the length of the sequence you want to generate\nseq_length = 10\ngenerated_seq = model.sample(n_samples=seq_length)\n\n# Step 5: Decoding\n# Decode the generated sequence of hidden states\nhidden_states = generated_seq[1]\n# Map hidden states to human activities based on emission probabilities\n# You need to define the mapping based on your trained model\n# For simplicity, let's assume a one-to-one mapping\n# Replace this with your actual decoding logic\ndecoded_sequence = hidden_states\n\n# Step 6: Evaluation\n# Evaluate the generated sequence (compare with original dataset)\n# Compute metrics like accuracy, precision, recall, etc.\n\n# Example of printing the decoded sequence\nprint(\"Generated Sequence:\")\nprint(decoded_sequence)\n","metadata":{},"execution_count":40,"outputs":[{"name":"stderr","output_type":"stream","text":"C:\\Users\\RIMPLE\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n\n  warnings.warn(\n"},{"name":"stdout","output_type":"stream","text":"Generated Sequence:\n\n[2 3 2 3 2 3 0 4 1 4]\n"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nfrom hmmlearn import hmm\nfrom sklearn.preprocessing import LabelEncoder\n\n# Step 1: Data Preprocessing\n# Load dataset\ndata = pd.read_csv(\"Travel details dataset.csv\")\n\n# Clean dataset (remove missing values, outliers, etc.)\ndata.dropna(inplace=True)\n\n# Encode categorical variables\nlabel_encoders = {}\nfor column in [\"Location\", \"Gender\"]:\n    label_encoders[column] = LabelEncoder()\n    data[column] = label_encoders[column].fit_transform(data[column])\n\n# Step 2: Feature Engineering\n# Select relevant features\nselected_features = [\"Duration\", \"Age\"] \nX = data[selected_features].values\n\n# Normalize numerical features\nX = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n\n# Step 3: Training the HMM\nn_states = 5\nmodel = hmm.GaussianHMM(n_components=n_states, covariance_type=\"full\", n_iter=100)\nmodel.fit(X)\n\n# Step 4: Generating Sequences\nseq_length = 10\ngenerated_seq, _ = model.sample(n_samples=seq_length)\n\n# Step 5: Decoding\ndecoded_sequence = model.predict(generated_seq)\n\n# Step 6: Decode hidden states to original string values\ndecoded_sequence_strings = []\nfor state in decoded_sequence:\n    decoded_sequence_strings.append(label_encoders[\"Location\"].inverse_transform([state])[0])\n\n# Print the decoded sequence\nprint(\"Decoded Sequence (Original Values):\")\nprint(decoded_sequence_strings)","metadata":{},"execution_count":4,"outputs":[{"name":"stdout","output_type":"stream","text":"Decoded Sequence (Original Values):\n\n['Amsterdam', 'Australia', 'Australia', 'Australia', 'Australia', 'Auckland, New Zealand', 'Amsterdam, Netherlands', 'Auckland, New Zealand', 'Amsterdam, Netherlands', 'Athens, Greece']\n"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nfrom hmmlearn import hmm\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\n# Step 1: Data Preprocessing\n# Load dataset\ndata = pd.read_csv(\"Travel details dataset.csv\")\n\n# Clean dataset (remove missing values, outliers, etc.)\ndata.dropna(inplace=True)\n\n# Encode categorical variables\nlabel_encoders = {}\nfor column in [\"Location\", \"Gender\"]:\n    label_encoders[column] = LabelEncoder()\n    data[column] = label_encoders[column].fit_transform(data[column])\n\n# Step 2: Feature Engineering\n# Select relevant features\nselected_features = [\"Duration\", \"Age\"] \nX = data[selected_features].values\n\n# Normalize numerical features\nX = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n\n# Step 3: Training and Evaluation using Cross-Validation\nn_states = 5\naccuracy_scores = []\nnum_folds = 5  # Number of folds for cross-validation\n\n# Perform cross-validation\nfor _ in range(num_folds):\n    # Split data into training and test sets\n    X_train, X_test = train_test_split(X, test_size=0.2, random_state=np.random.randint(100))\n    \n    # Train the HMM model\n    model = hmm.GaussianHMM(n_components=n_states, covariance_type=\"full\", n_iter=100)\n    model.fit(X_train)\n    \n    # Generate sequences and decode\n    seq_length = len(X_test)  # Use the length of the test set\n    generated_seq, _ = model.sample(n_samples=seq_length)\n    decoded_sequence = model.predict(generated_seq)\n    \n    # Decode hidden states to original string values\n    decoded_sequence_strings = label_encoders[\"Location\"].inverse_transform(decoded_sequence)\n    \n    # Compute accuracy\n    accuracy = accuracy_score(label_encoders[\"Location\"].inverse_transform(model.predict(X_test)), decoded_sequence_strings)\n    accuracy_scores.append(accuracy)\n\n# Calculate average accuracy\naverage_accuracy = np.mean(accuracy_scores)\nprint(\"Average Accuracy:\", average_accuracy)\n","metadata":{},"execution_count":3,"outputs":[{"name":"stdout","output_type":"stream","text":"Average Accuracy: 0.3142857142857142\n"}]},{"cell_type":"code","source":"import numpy as np\nfrom hmmlearn import hmm\nfrom sklearn.preprocessing import LabelEncoder\nimport pandas as pd\n\n# Initialize lists to store valid data\ntrip_durations = []\nuser_types = []\ngenders = []\nbirth_years = []\n\n# Load data from CSV file\nwith open('trip.csv', 'r') as file:\n    for line_number, line in enumerate(file, start=1):\n        # Skip header\n        if line_number == 1:\n            continue\n        # Attempt to parse the line\n        try:\n            fields = line.strip().split(',')\n            if len(fields) != 12:  # Check if the number of fields matches the expected\n                raise ValueError(f\"Expected 12 fields, found {len(fields)} fields\")\n            trip_durations.append(float(fields[4]))  # Assuming tripduration is the 5th field\n            user_types.append(fields[9])  # Assuming usertype is the 10th field\n            genders.append(fields[10])  # Assuming gender is the 11th field\n            birth_years.append(fields[11])  # Assuming birthyear is the 12th field\n        except Exception as e:\n            print(f\"Error processing line {line_number}: {e}\")\n\n# Encode states (e.g., user types, genders, etc.)\nlabel_encoder = LabelEncoder()\nencoded_user_types = label_encoder.fit_transform(user_types)\nencoded_genders = label_encoder.fit_transform(genders)\nencoded_birth_years = label_encoder.fit_transform(birth_years)\n\n# Combine features\nX = np.column_stack([trip_durations, encoded_user_types, encoded_genders, encoded_birth_years])\n\n# Create and fit HMM\nmodel = hmm.GaussianHMM(n_components=2, covariance_type=\"full\", n_iter=100)\nmodel.fit(X)\n\n# Predict states\nhidden_states = model.predict(X)\n\n# Calculate accuracy if ground truth is available\n# accuracy = np.mean(hidden_states == ground_truth)\n# print(\"Accuracy:\", accuracy)\n\n# Generate a sequence\nsequence = hidden_states\nprint(\"Generated sequence:\", sequence)\n","metadata":{},"execution_count":9,"outputs":[{"name":"stdout","output_type":"stream","text":"Error processing line 50794: Expected 12 fields, found 20 fields\n"},{"name":"stderr","output_type":"stream","text":"Model is not converging.  Current: 131873.69181339158 is not greater than 131873.6918134356. Delta is -4.4034095481038094e-08\n"},{"name":"stdout","output_type":"stream","text":"Generated sequence: [0 0 0 ... 1 1 1]\n"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}